{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ann heart stroke.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPINzqoQK5RjHoNd933Cspc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sriramofficial9/deep-learning/blob/main/ann_heart_stroke.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwtO69cmlS6o"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz6tCuIglfCw"
      },
      "source": [
        "ds=pd.read_csv('/content/heart.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqkwnVKXlkfC",
        "outputId": "c228dcde-beeb-4d21-891e-21bb873af570"
      },
      "source": [
        "ds.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Ubem2UzDlmmh",
        "outputId": "657b8e0c-4408-41b7-f2ab-97b050b5f6ff"
      },
      "source": [
        "ds.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trtbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalachh</th>\n",
              "      <th>exng</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slp</th>\n",
              "      <th>caa</th>\n",
              "      <th>thall</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trtbps  chol  fbs  ...  exng  oldpeak  slp  caa  thall  output\n",
              "0   63    1   3     145   233    1  ...     0      2.3    0    0      1       1\n",
              "1   37    1   2     130   250    0  ...     0      3.5    0    0      2       1\n",
              "2   41    0   1     130   204    0  ...     0      1.4    2    0      2       1\n",
              "3   56    1   1     120   236    0  ...     0      0.8    2    0      2       1\n",
              "4   57    0   0     120   354    0  ...     1      0.6    2    0      2       1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCtY34ZRl8zW",
        "outputId": "a9498c12-53e8-4a1a-b865-9136c3eb46cf"
      },
      "source": [
        "null_columns=ds.columns[ds.isnull().any()]\n",
        "ds[null_columns].isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], dtype: float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1-z3oh_mdKK"
      },
      "source": [
        "X = ds.drop('output',1)\n",
        "y = ds['output']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNwK3ey4uxA9",
        "outputId": "299689a7-665d-4e22-9f83-1faaf3e93f35"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j25UThy-u06K",
        "outputId": "f950d2ab-ec07-4b5c-f1ad-c03655059f99"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF0CIRrpnaFh"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19baVW5YrYAy"
      },
      "source": [
        "col_scale=['age','cp','trtbps','chol','thalachh','oldpeak','slp','thall','caa']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "294_Yv_Lrczt",
        "outputId": "89a5ddbc-c8db-445e-849e-96887d34105d"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train[col_scale] = sc.fit_transform(X_train[col_scale])\n",
        "X_test[col_scale] = sc.transform(X_test[col_scale])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1734: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value[:, i].tolist())\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1734: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value[:, i].tolist())\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd2arzPaujyo",
        "outputId": "13c6adf0-3de8-4674-80d4-837d813493bc"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(242, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzSlkupmupU-",
        "outputId": "24db6829-e236-4519-8685-0191d8539d81"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(242,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "oP1-rTm2r_YY",
        "outputId": "28d1c99e-b17d-48c4-a923-c936ed23003c"
      },
      "source": [
        "X_train.sample(25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trtbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalachh</th>\n",
              "      <th>exng</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slp</th>\n",
              "      <th>caa</th>\n",
              "      <th>thall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>-0.052010</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.958008</td>\n",
              "      <td>-0.424794</td>\n",
              "      <td>0.381849</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.723609</td>\n",
              "      <td>1</td>\n",
              "      <td>1.073784</td>\n",
              "      <td>-0.668965</td>\n",
              "      <td>0.271607</td>\n",
              "      <td>1.167074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>0.385781</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.958008</td>\n",
              "      <td>2.222915</td>\n",
              "      <td>-0.415774</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.149917</td>\n",
              "      <td>1</td>\n",
              "      <td>1.621233</td>\n",
              "      <td>-0.668965</td>\n",
              "      <td>1.267500</td>\n",
              "      <td>-2.117019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.495228</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.958008</td>\n",
              "      <td>0.208354</td>\n",
              "      <td>-0.240686</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.488066</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.477321</td>\n",
              "      <td>-0.668965</td>\n",
              "      <td>-0.724286</td>\n",
              "      <td>1.167074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>0.823571</td>\n",
              "      <td>1</td>\n",
              "      <td>0.020211</td>\n",
              "      <td>-0.655030</td>\n",
              "      <td>0.673662</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.978803</td>\n",
              "      <td>0</td>\n",
              "      <td>0.343852</td>\n",
              "      <td>-0.668965</td>\n",
              "      <td>0.271607</td>\n",
              "      <td>1.167074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>-0.270906</td>\n",
              "      <td>1</td>\n",
              "      <td>1.976649</td>\n",
              "      <td>1.186855</td>\n",
              "      <td>1.004384</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.211114</td>\n",
              "      <td>0</td>\n",
              "      <td>0.161369</td>\n",
              "      <td>-0.668965</td>\n",
              "      <td>-0.724286</td>\n",
              "      <td>1.167074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>0.495228</td>\n",
              "      <td>1</td>\n",
              "      <td>0.020211</td>\n",
              "      <td>0.496148</td>\n",
              "      <td>-0.493590</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.615663</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.933529</td>\n",
              "      <td>0.966282</td>\n",
              "      <td>-0.724286</td>\n",
              "      <td>-0.474972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>0.166885</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.958008</td>\n",
              "      <td>0.150795</td>\n",
              "      <td>3.163802</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.020212</td>\n",
              "      <td>1</td>\n",
              "      <td>0.800060</td>\n",
              "      <td>-0.668965</td>\n",
              "      <td>1.267500</td>\n",
              "      <td>1.167074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>-1.255935</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.958008</td>\n",
              "      <td>-0.655030</td>\n",
              "      <td>-1.349576</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.255755</td>\n",
              "      <td>1</td>\n",
              "      <td>1.347508</td>\n",
              "      <td>-0.668965</td>\n",
              "      <td>-0.724286</td>\n",
              "      <td>1.167074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>0.385781</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.958008</td>\n",
              "      <td>-1.806207</td>\n",
              "      <td>-0.240686</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.275405</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.842287</td>\n",
              "      <td>0.966282</td>\n",
              "      <td>0.271607</td>\n",
              "      <td>1.167074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.270906</td>\n",
              "      <td>1</td>\n",
              "      <td>0.998430</td>\n",
              "      <td>2.338032</td>\n",
              "      <td>-0.921583</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.530598</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.477321</td>\n",
              "      <td>0.966282</td>\n",
              "      <td>-0.724286</td>\n",
              "      <td>1.167074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>-1.584278</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.958008</td>\n",
              "      <td>-1.230618</td>\n",
              "      <td>-1.544118</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.510948</td>\n",
              "      <td>1</td>\n",
              "      <td>0.891301</td>\n",
              "      <td>-0.668965</td>\n",
              "      <td>-0.724286</td>\n",
              "      <td>1.167074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>-0.708697</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.958008</td>\n",
              "      <td>-0.539912</td>\n",
              "      <td>-0.474136</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.551371</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.933529</td>\n",
              "      <td>0.966282</td>\n",
              "      <td>-0.724286</td>\n",
              "      <td>-0.474972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.589706</td>\n",
              "      <td>0</td>\n",
              "      <td>1.976649</td>\n",
              "      <td>0.496148</td>\n",
              "      <td>-0.143415</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.062744</td>\n",
              "      <td>0</td>\n",
              "      <td>0.708818</td>\n",
              "      <td>0.966282</td>\n",
              "      <td>1.267500</td>\n",
              "      <td>-0.474972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>0.276333</td>\n",
              "      <td>1</td>\n",
              "      <td>0.998430</td>\n",
              "      <td>-0.194559</td>\n",
              "      <td>-0.337957</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.020212</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.568563</td>\n",
              "      <td>-0.668965</td>\n",
              "      <td>0.271607</td>\n",
              "      <td>1.167074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>-2.788203</td>\n",
              "      <td>1</td>\n",
              "      <td>0.020211</td>\n",
              "      <td>-0.079441</td>\n",
              "      <td>-0.824312</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.231887</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.933529</td>\n",
              "      <td>0.966282</td>\n",
              "      <td>-0.724286</td>\n",
              "      <td>-0.474972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>-0.052010</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.958008</td>\n",
              "      <td>-1.230618</td>\n",
              "      <td>-0.143415</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.000562</td>\n",
              "      <td>1</td>\n",
              "      <td>1.621233</td>\n",
              "      <td>-0.668965</td>\n",
              "      <td>0.271607</td>\n",
              "      <td>1.167074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>-0.052010</td>\n",
              "      <td>0</td>\n",
              "      <td>0.998430</td>\n",
              "      <td>1.647326</td>\n",
              "      <td>-0.882675</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.573130</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.933529</td>\n",
              "      <td>0.966282</td>\n",
              "      <td>0.271607</td>\n",
              "      <td>-0.474972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>0.385781</td>\n",
              "      <td>1</td>\n",
              "      <td>0.998430</td>\n",
              "      <td>0.496148</td>\n",
              "      <td>-0.688133</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.658195</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.933529</td>\n",
              "      <td>0.966282</td>\n",
              "      <td>-0.724286</td>\n",
              "      <td>-0.474972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>-1.037040</td>\n",
              "      <td>0</td>\n",
              "      <td>0.020211</td>\n",
              "      <td>-0.079441</td>\n",
              "      <td>-0.240686</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.083517</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.386080</td>\n",
              "      <td>-0.668965</td>\n",
              "      <td>-0.724286</td>\n",
              "      <td>-0.474972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>-0.380353</td>\n",
              "      <td>0</td>\n",
              "      <td>0.998430</td>\n",
              "      <td>0.496148</td>\n",
              "      <td>1.198926</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.320046</td>\n",
              "      <td>0</td>\n",
              "      <td>0.435094</td>\n",
              "      <td>0.966282</td>\n",
              "      <td>0.271607</td>\n",
              "      <td>-0.474972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>-0.927592</td>\n",
              "      <td>1</td>\n",
              "      <td>0.020211</td>\n",
              "      <td>-1.748648</td>\n",
              "      <td>-0.960492</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.275405</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.933529</td>\n",
              "      <td>0.966282</td>\n",
              "      <td>-0.724286</td>\n",
              "      <td>1.167074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>-0.380353</td>\n",
              "      <td>1</td>\n",
              "      <td>0.998430</td>\n",
              "      <td>-1.806207</td>\n",
              "      <td>-0.474136</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.277514</td>\n",
              "      <td>1</td>\n",
              "      <td>0.161369</td>\n",
              "      <td>-0.668965</td>\n",
              "      <td>-0.724286</td>\n",
              "      <td>-0.474972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>0.604676</td>\n",
              "      <td>0</td>\n",
              "      <td>0.998430</td>\n",
              "      <td>-0.655030</td>\n",
              "      <td>-1.330122</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-2.276528</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.933529</td>\n",
              "      <td>0.966282</td>\n",
              "      <td>-0.724286</td>\n",
              "      <td>-0.474972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1.808601</td>\n",
              "      <td>0</td>\n",
              "      <td>0.020211</td>\n",
              "      <td>1.647326</td>\n",
              "      <td>1.082201</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.530598</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.568563</td>\n",
              "      <td>0.966282</td>\n",
              "      <td>1.267500</td>\n",
              "      <td>-0.474972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>1.151915</td>\n",
              "      <td>0</td>\n",
              "      <td>0.998430</td>\n",
              "      <td>1.359531</td>\n",
              "      <td>0.440212</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.064853</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.203597</td>\n",
              "      <td>0.966282</td>\n",
              "      <td>-0.724286</td>\n",
              "      <td>-0.474972</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          age  sex        cp    trtbps  ...   oldpeak       slp       caa     thall\n",
              "187 -0.052010    1 -0.958008 -0.424794  ...  1.073784 -0.668965  0.271607  1.167074\n",
              "292  0.385781    0 -0.958008  2.222915  ...  1.621233 -0.668965  1.267500 -2.117019\n",
              "20   0.495228    1 -0.958008  0.208354  ... -0.477321 -0.668965 -0.724286  1.167074\n",
              "226  0.823571    1  0.020211 -0.655030  ...  0.343852 -0.668965  0.271607  1.167074\n",
              "83  -0.270906    1  1.976649  1.186855  ...  0.161369 -0.668965 -0.724286  1.167074\n",
              "77   0.495228    1  0.020211  0.496148  ... -0.933529  0.966282 -0.724286 -0.474972\n",
              "246  0.166885    0 -0.958008  0.150795  ...  0.800060 -0.668965  1.267500  1.167074\n",
              "178 -1.255935    1 -0.958008 -0.655030  ...  1.347508 -0.668965 -0.724286  1.167074\n",
              "273  0.385781    1 -0.958008 -1.806207  ... -0.842287  0.966282  0.271607  1.167074\n",
              "8   -0.270906    1  0.998430  2.338032  ... -0.477321  0.966282 -0.724286  1.167074\n",
              "175 -1.584278    1 -0.958008 -1.230618  ...  0.891301 -0.668965 -0.724286  1.167074\n",
              "56  -0.708697    1 -0.958008 -0.539912  ... -0.933529  0.966282 -0.724286 -0.474972\n",
              "19   1.589706    0  1.976649  0.496148  ...  0.708818  0.966282  1.267500 -0.474972\n",
              "210  0.276333    1  0.998430 -0.194559  ... -0.568563 -0.668965  0.271607  1.167074\n",
              "72  -2.788203    1  0.020211 -0.079441  ... -0.933529  0.966282 -0.724286 -0.474972\n",
              "224 -0.052010    1 -0.958008 -1.230618  ...  1.621233 -0.668965  0.271607  1.167074\n",
              "130 -0.052010    0  0.998430  1.647326  ... -0.933529  0.966282  0.271607 -0.474972\n",
              "64   0.385781    1  0.998430  0.496148  ... -0.933529  0.966282 -0.724286 -0.474972\n",
              "67  -1.037040    0  0.020211 -0.079441  ... -0.386080 -0.668965 -0.724286 -0.474972\n",
              "40  -0.380353    0  0.998430  0.496148  ...  0.435094  0.966282  0.271607 -0.474972\n",
              "87  -0.927592    1  0.020211 -1.748648  ... -0.933529  0.966282 -0.724286  1.167074\n",
              "66  -0.380353    1  0.998430 -1.806207  ...  0.161369 -0.668965 -0.724286 -0.474972\n",
              "136  0.604676    0  0.998430 -0.655030  ... -0.933529  0.966282 -0.724286 -0.474972\n",
              "25   1.808601    0  0.020211  1.647326  ... -0.568563  0.966282  1.267500 -0.474972\n",
              "38   1.151915    0  0.998430  1.359531  ... -0.203597  0.966282 -0.724286 -0.474972\n",
              "\n",
              "[25 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTRZSbYtsAuI"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sbz20xq_s9TN",
        "outputId": "dca7d290-100e-441a-b8fa-2d755403551b"
      },
      "source": [
        "model=keras.Sequential(\n",
        "    [\n",
        "     keras.layers.Dense(units=13,input_shape=(13,),activation='relu'),\n",
        "     keras.layers.Dense(units=10,activation='relu'),\n",
        "     keras.layers.Dense(units=6,activation='relu'),\n",
        "     \n",
        "     \n",
        "     keras.layers.Dense(units=1,activation='sigmoid')\n",
        "    ]\n",
        ")\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X_train,y_train,epochs=120)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6990 - accuracy: 0.5124\n",
            "Epoch 2/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.6240\n",
            "Epoch 3/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.6777\n",
            "Epoch 4/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6409 - accuracy: 0.7397\n",
            "Epoch 5/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.7727\n",
            "Epoch 6/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6057 - accuracy: 0.7851\n",
            "Epoch 7/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.7934\n",
            "Epoch 8/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.8017\n",
            "Epoch 9/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.8058\n",
            "Epoch 10/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.8058\n",
            "Epoch 11/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7934\n",
            "Epoch 12/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.8058\n",
            "Epoch 13/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.8140\n",
            "Epoch 14/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.8182\n",
            "Epoch 15/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8264\n",
            "Epoch 16/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8264\n",
            "Epoch 17/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8388\n",
            "Epoch 18/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8512\n",
            "Epoch 19/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3745 - accuracy: 0.8512\n",
            "Epoch 20/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8471\n",
            "Epoch 21/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8636\n",
            "Epoch 22/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8678\n",
            "Epoch 23/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8678\n",
            "Epoch 24/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8719\n",
            "Epoch 25/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8719\n",
            "Epoch 26/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3245 - accuracy: 0.8760\n",
            "Epoch 27/120\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3197 - accuracy: 0.8843\n",
            "Epoch 28/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8802\n",
            "Epoch 29/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8802\n",
            "Epoch 30/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3059 - accuracy: 0.8843\n",
            "Epoch 31/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8967\n",
            "Epoch 32/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8926\n",
            "Epoch 33/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.8884\n",
            "Epoch 34/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2895 - accuracy: 0.8926\n",
            "Epoch 35/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.8926\n",
            "Epoch 36/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2821 - accuracy: 0.8967\n",
            "Epoch 37/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2786 - accuracy: 0.8967\n",
            "Epoch 38/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2750 - accuracy: 0.8967\n",
            "Epoch 39/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2719 - accuracy: 0.8967\n",
            "Epoch 40/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2690 - accuracy: 0.8967\n",
            "Epoch 41/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2662 - accuracy: 0.9008\n",
            "Epoch 42/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2633 - accuracy: 0.9008\n",
            "Epoch 43/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.9008\n",
            "Epoch 44/120\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2586 - accuracy: 0.9008\n",
            "Epoch 45/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2554 - accuracy: 0.9008\n",
            "Epoch 46/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 0.9008\n",
            "Epoch 47/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.9091\n",
            "Epoch 48/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.9091\n",
            "Epoch 49/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.9091\n",
            "Epoch 50/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.9174\n",
            "Epoch 51/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 0.9174\n",
            "Epoch 52/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2382 - accuracy: 0.9174\n",
            "Epoch 53/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.9215\n",
            "Epoch 54/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9174\n",
            "Epoch 55/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9215\n",
            "Epoch 56/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9256\n",
            "Epoch 57/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9256\n",
            "Epoch 58/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.9298\n",
            "Epoch 59/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9256\n",
            "Epoch 60/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2221 - accuracy: 0.9256\n",
            "Epoch 61/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2201 - accuracy: 0.9298\n",
            "Epoch 62/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9339\n",
            "Epoch 63/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9339\n",
            "Epoch 64/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9339\n",
            "Epoch 65/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9298\n",
            "Epoch 66/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2121 - accuracy: 0.9298\n",
            "Epoch 67/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.9380\n",
            "Epoch 68/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9339\n",
            "Epoch 69/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9339\n",
            "Epoch 70/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2051 - accuracy: 0.9339\n",
            "Epoch 71/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2031 - accuracy: 0.9339\n",
            "Epoch 72/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2019 - accuracy: 0.9339\n",
            "Epoch 73/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1995 - accuracy: 0.9380\n",
            "Epoch 74/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9339\n",
            "Epoch 75/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1966 - accuracy: 0.9339\n",
            "Epoch 76/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1952 - accuracy: 0.9421\n",
            "Epoch 77/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1932 - accuracy: 0.9380\n",
            "Epoch 78/120\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1915 - accuracy: 0.9421\n",
            "Epoch 79/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9463\n",
            "Epoch 80/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1881 - accuracy: 0.9463\n",
            "Epoch 81/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9463\n",
            "Epoch 82/120\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1850 - accuracy: 0.9463\n",
            "Epoch 83/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9463\n",
            "Epoch 84/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1810 - accuracy: 0.9463\n",
            "Epoch 85/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9463\n",
            "Epoch 86/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1777 - accuracy: 0.9463\n",
            "Epoch 87/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.9463\n",
            "Epoch 88/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1761 - accuracy: 0.9463\n",
            "Epoch 89/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1728 - accuracy: 0.9463\n",
            "Epoch 90/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.9463\n",
            "Epoch 91/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1698 - accuracy: 0.9463\n",
            "Epoch 92/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1691 - accuracy: 0.9463\n",
            "Epoch 93/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1670 - accuracy: 0.9463\n",
            "Epoch 94/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9463\n",
            "Epoch 95/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1650 - accuracy: 0.9463\n",
            "Epoch 96/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1621 - accuracy: 0.9463\n",
            "Epoch 97/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.9463\n",
            "Epoch 98/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1602 - accuracy: 0.9463\n",
            "Epoch 99/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1590 - accuracy: 0.9463\n",
            "Epoch 100/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1569 - accuracy: 0.9463\n",
            "Epoch 101/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9463\n",
            "Epoch 102/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1542 - accuracy: 0.9463\n",
            "Epoch 103/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1525 - accuracy: 0.9463\n",
            "Epoch 104/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9463\n",
            "Epoch 105/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1500 - accuracy: 0.9421\n",
            "Epoch 106/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9421\n",
            "Epoch 107/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1467 - accuracy: 0.9421\n",
            "Epoch 108/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9463\n",
            "Epoch 109/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.9421\n",
            "Epoch 110/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1438 - accuracy: 0.9504\n",
            "Epoch 111/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1416 - accuracy: 0.9504\n",
            "Epoch 112/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1397 - accuracy: 0.9504\n",
            "Epoch 113/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1387 - accuracy: 0.9545\n",
            "Epoch 114/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9587\n",
            "Epoch 115/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1359 - accuracy: 0.9504\n",
            "Epoch 116/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1344 - accuracy: 0.9545\n",
            "Epoch 117/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1333 - accuracy: 0.9545\n",
            "Epoch 118/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1322 - accuracy: 0.9587\n",
            "Epoch 119/120\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1304 - accuracy: 0.9628\n",
            "Epoch 120/120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1291 - accuracy: 0.9669\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0a4146a110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sdch1l6ZtUvH",
        "outputId": "56b04e7f-88ae-4aff-8f43-9d4cecaeb733"
      },
      "source": [
        "y_pred=model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f0a4131d830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.74734402e-04],\n",
              "       [3.99757713e-01],\n",
              "       [1.53182447e-02],\n",
              "       [8.18654895e-03],\n",
              "       [4.08351421e-04],\n",
              "       [8.64624977e-04],\n",
              "       [5.66244125e-04],\n",
              "       [9.07928824e-01],\n",
              "       [6.46412373e-04],\n",
              "       [9.97936964e-01],\n",
              "       [6.47027850e-01],\n",
              "       [1.28710330e-01],\n",
              "       [9.73902464e-01],\n",
              "       [6.12763464e-01],\n",
              "       [1.03679180e-01],\n",
              "       [7.75227606e-01],\n",
              "       [9.24266577e-01],\n",
              "       [1.38714910e-03],\n",
              "       [9.44589555e-01],\n",
              "       [9.69256163e-01],\n",
              "       [9.93060172e-01],\n",
              "       [1.86485052e-03],\n",
              "       [9.04464126e-01],\n",
              "       [8.32926273e-01],\n",
              "       [9.99836504e-01],\n",
              "       [9.04516101e-01],\n",
              "       [1.47427320e-02],\n",
              "       [9.95168328e-01],\n",
              "       [7.96632469e-01],\n",
              "       [9.84862685e-01],\n",
              "       [9.99763608e-01],\n",
              "       [9.92880464e-01],\n",
              "       [5.91134608e-01],\n",
              "       [9.46529508e-01],\n",
              "       [1.84929371e-02],\n",
              "       [9.45256233e-01],\n",
              "       [1.63670778e-02],\n",
              "       [1.02760404e-01],\n",
              "       [8.81392062e-02],\n",
              "       [1.04883015e-02],\n",
              "       [9.97030973e-01],\n",
              "       [5.84458411e-02],\n",
              "       [1.44801348e-01],\n",
              "       [1.71865474e-06],\n",
              "       [9.97060478e-01],\n",
              "       [9.25807118e-01],\n",
              "       [1.21103555e-01],\n",
              "       [9.96515155e-01],\n",
              "       [5.70782423e-01],\n",
              "       [8.29331279e-02],\n",
              "       [9.99669731e-01],\n",
              "       [8.80928159e-01],\n",
              "       [9.49953198e-01],\n",
              "       [6.70418859e-01],\n",
              "       [9.51264501e-01],\n",
              "       [9.96772885e-01],\n",
              "       [7.14628279e-01],\n",
              "       [4.27371264e-03],\n",
              "       [9.99428749e-01],\n",
              "       [5.99066019e-02],\n",
              "       [6.12694621e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNQz2zfMuWr0",
        "outputId": "d1a41a7b-5fd4-45a6-fb6d-2f58bb99b219"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(61, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q_RRUS8tyk8"
      },
      "source": [
        "y_final = []\n",
        "for element in y_pred:\n",
        "    if element > 0.5:\n",
        "        y_final.append(1)\n",
        "    else:\n",
        "        y_final.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgXsSTcPtzrM",
        "outputId": "4e53d247-b318-4dfb-910f-b6d2f415cdcf"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_final)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[20 10]\n",
            " [ 6 25]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7377049180327869"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "a49WFvjjt3xR",
        "outputId": "6a702510-1d51-4049-9c59-983f8f530834"
      },
      "source": [
        "\n",
        "import seaborn as sn\n",
        "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_final)\n",
        "\n",
        "plt.figure(figsize = (12,7))\n",
        "sn.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(87.0, 0.5, 'Truth')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}